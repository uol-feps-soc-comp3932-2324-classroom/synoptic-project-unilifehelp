{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_27816\\2769020576.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Importing metadata zip file and converting it to dataframe\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def getDF(path):\n",
    "  # Unzip the file, load in each line as an object\n",
    "  g = gzip.open(path, 'rb')\n",
    "  g = [json.loads(l) for l in g]\n",
    "\n",
    "  # Map to a dictionary, then load in as a dataframe\n",
    "  dict_df = {i: d for (i, d) in enumerate(g)}\n",
    "  return pd.DataFrame.from_dict(dict_df, orient='index')\n",
    "\n",
    "df = getDF('meta_ALL_Beauty.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32892</td>\n",
       "      <td>32892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13751</td>\n",
       "      <td>32488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[]</td>\n",
       "      <td>B00027CDOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description        asin\n",
       "count        32892       32892\n",
       "unique       13751       32488\n",
       "top             []  B00027CDOW\n",
       "freq         17773           2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Selecting only the colums that are required for analysis\n",
    "\n",
    "colums_description_asin = [\"description\",\"asin\"]\n",
    "df = df[colums_description_asin]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptions in the json file are a list of strings, converting to sting for easy cleaning\n",
    "df[\"newdescription\"] = df.description.map(lambda x: \".\".join(x).replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty descriptions\n",
    "#df = df.drop(df[df[\"newdescription\"] == \"\"].index)\n",
    "\n",
    "#print(len(df)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>asin</th>\n",
       "      <th>newdescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Loud 'N Clear Personal Sound Amplifier allows...</td>\n",
       "      <td>6546546450</td>\n",
       "      <td>Loud 'N Clear Personal Sound Amplifier allows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[No7 Lift &amp; Luminate Triple Action Serum 50ml ...</td>\n",
       "      <td>7178680776</td>\n",
       "      <td>No7 Lift &amp; Luminate Triple Action Serum 50ml b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[No7 Stay Perfect Foundation now stays perfect...</td>\n",
       "      <td>7250468162</td>\n",
       "      <td>No7 Stay Perfect Foundation now stays perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Lacto Calamine Skin Balance Daily Nourishing ...</td>\n",
       "      <td>7414204790</td>\n",
       "      <td>Lacto Calamine Skin Balance Daily Nourishing L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Mary Kay Satin Hands Peach Hand Cream Travel ...</td>\n",
       "      <td>7535842801</td>\n",
       "      <td>Mary Kay Satin Hands Peach Hand Cream Travel S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32880</th>\n",
       "      <td>[Move over soap on a rope! This heavy-duty Bri...</td>\n",
       "      <td>B01HIHLFOC</td>\n",
       "      <td>Move over soap on a rope! This heavy-duty Bric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32884</th>\n",
       "      <td>[Eau de parfum spray vial mini design house: y...</td>\n",
       "      <td>B01HIPOQ2M</td>\n",
       "      <td>Eau de parfum spray vial mini design house: yv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32885</th>\n",
       "      <td>[Pokemon Plush 9.2 Inch / 23cm Gengar Doll Stu...</td>\n",
       "      <td>B01HIUEEHO</td>\n",
       "      <td>Pokemon Plush 9.2 Inch / 23cm Gengar Doll Stuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32886</th>\n",
       "      <td>[New and unused product. 100% authentic Benefi...</td>\n",
       "      <td>B01HIWKGOM</td>\n",
       "      <td>New and unused product. 100% authentic Benefit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32890</th>\n",
       "      <td>[Brand new and high quality&lt;br&gt; Enables fast v...</td>\n",
       "      <td>B01HJASD20</td>\n",
       "      <td>Brand new and high quality&lt;br&gt; Enables fast vo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description        asin  \\\n",
       "0      [Loud 'N Clear Personal Sound Amplifier allows...  6546546450   \n",
       "1      [No7 Lift & Luminate Triple Action Serum 50ml ...  7178680776   \n",
       "2      [No7 Stay Perfect Foundation now stays perfect...  7250468162   \n",
       "4      [Lacto Calamine Skin Balance Daily Nourishing ...  7414204790   \n",
       "5      [Mary Kay Satin Hands Peach Hand Cream Travel ...  7535842801   \n",
       "...                                                  ...         ...   \n",
       "32880  [Move over soap on a rope! This heavy-duty Bri...  B01HIHLFOC   \n",
       "32884  [Eau de parfum spray vial mini design house: y...  B01HIPOQ2M   \n",
       "32885  [Pokemon Plush 9.2 Inch / 23cm Gengar Doll Stu...  B01HIUEEHO   \n",
       "32886  [New and unused product. 100% authentic Benefi...  B01HIWKGOM   \n",
       "32890  [Brand new and high quality<br> Enables fast v...  B01HJASD20   \n",
       "\n",
       "                                          newdescription  \n",
       "0      Loud 'N Clear Personal Sound Amplifier allows ...  \n",
       "1      No7 Lift & Luminate Triple Action Serum 50ml b...  \n",
       "2      No7 Stay Perfect Foundation now stays perfect ...  \n",
       "4      Lacto Calamine Skin Balance Daily Nourishing L...  \n",
       "5      Mary Kay Satin Hands Peach Hand Cream Travel S...  \n",
       "...                                                  ...  \n",
       "32880  Move over soap on a rope! This heavy-duty Bric...  \n",
       "32884  Eau de parfum spray vial mini design house: yv...  \n",
       "32885  Pokemon Plush 9.2 Inch / 23cm Gengar Doll Stuf...  \n",
       "32886  New and unused product. 100% authentic Benefit...  \n",
       "32890  Brand new and high quality<br> Enables fast vo...  \n",
       "\n",
       "[15108 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df[ ( (df[\"newdescription\"] == \"\" ) | ( df[\"newdescription\"].isnull()) ) ].index)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>asin</th>\n",
       "      <th>newdescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14821</td>\n",
       "      <td>14821</td>\n",
       "      <td>14821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13749</td>\n",
       "      <td>14821</td>\n",
       "      <td>13743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[For over 60 years, Betty Dain Creations, Inc....</td>\n",
       "      <td>6546546450</td>\n",
       "      <td>For over 60 years, Betty Dain Creations, Inc. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description        asin  \\\n",
       "count                                               14821       14821   \n",
       "unique                                              13749       14821   \n",
       "top     [For over 60 years, Betty Dain Creations, Inc....  6546546450   \n",
       "freq                                                   59           1   \n",
       "\n",
       "                                           newdescription  \n",
       "count                                               14821  \n",
       "unique                                              13743  \n",
       "top     For over 60 years, Betty Dain Creations, Inc. ...  \n",
       "freq                                                   59  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate asin so can have only unique products\n",
    "df[df.duplicated(\"asin\")]\n",
    "df = df.drop_duplicates(\"asin\", keep=\"last\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>asin</th>\n",
       "      <th>newdescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>[Loud 'N Clear Personal Sound Amplifier allows...</td>\n",
       "      <td>6546546450</td>\n",
       "      <td>Loud 'N Clear Personal Sound Amplifier allows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description        asin  \\\n",
       "count                                               13743       13743   \n",
       "unique                                              13743       13743   \n",
       "top     [Loud 'N Clear Personal Sound Amplifier allows...  6546546450   \n",
       "freq                                                    1           1   \n",
       "\n",
       "                                           newdescription  \n",
       "count                                               13743  \n",
       "unique                                              13743  \n",
       "top     Loud 'N Clear Personal Sound Amplifier allows ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate description\n",
    "df[df.duplicated(\"newdescription\")]\n",
    "df = df.drop_duplicates(\"newdescription\", keep=\"last\")\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newdescription</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13743</td>\n",
       "      <td>13743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loud 'N Clear Personal Sound Amplifier allows ...</td>\n",
       "      <td>6546546450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           newdescription        asin\n",
       "count                                               13743       13743\n",
       "unique                                              13743       13743\n",
       "top     Loud 'N Clear Personal Sound Amplifier allows ...  6546546450\n",
       "freq                                                    1           1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing redundant old description column\n",
    "colums_description_asin = [\"newdescription\",\"asin\"]\n",
    "df = df[colums_description_asin]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13743.000000\n",
       "mean        63.643600\n",
       "std         91.940065\n",
       "min          1.000000\n",
       "10%          7.000000\n",
       "15%          9.000000\n",
       "20%         11.000000\n",
       "25%         14.000000\n",
       "30%         17.000000\n",
       "50%         39.000000\n",
       "75%         79.000000\n",
       "85%        114.000000\n",
       "90%        148.000000\n",
       "92%        169.000000\n",
       "95%        217.000000\n",
       "97%        259.000000\n",
       "98%        288.000000\n",
       "99%        324.000000\n",
       "max       3224.000000\n",
       "Name: newdescription, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify range of descriptions in after duplicates removal\n",
    "\n",
    "df_descriptions_without_empty = df[\"newdescription\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_descriptions_without_empty.describe([0.1,0.15,0.20,0.25,0.30,0.75,0.85,0.90,0.92,0.95,0.97,0.98,0.99])\n",
    "\n",
    "# 97% upper limit of 259 (same % milit as reviews)\n",
    "# 11 words (same numbe of words as reviews) 20% because no assuption is made on how much more each one is informative as well as descriptions \n",
    "# being a smaller sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 10710\n",
       "unique                                                10710\n",
       "top       Loud 'N Clear Personal Sound Amplifier allows ...\n",
       "freq                                                      1\n",
       "Name: newdescription, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove descriptions with more or less than xx pre-cleaned words\n",
    "\n",
    "# Split at any white space \n",
    "df[\"num_words_description\"] = df[\"newdescription\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Check if under or equal to 80% upper limmit words fulfils withs condition and set it\n",
    "df = df[(df[\"num_words_description\"] <= 259) & (df[\"num_words_description\"] >= 11)]\n",
    "\n",
    "df[\"newdescription\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10710.000000\n",
       "mean        65.241923\n",
       "std         53.053433\n",
       "min         11.000000\n",
       "10%         15.000000\n",
       "15%         18.000000\n",
       "20%         23.000000\n",
       "25%         27.000000\n",
       "30%         31.000000\n",
       "50%         49.000000\n",
       "75%         86.000000\n",
       "85%        115.000000\n",
       "90%        142.000000\n",
       "92%        157.000000\n",
       "95%        185.000000\n",
       "97%        211.000000\n",
       "98%        225.000000\n",
       "99%        243.000000\n",
       "max        259.000000\n",
       "Name: newdescription, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shortening worked\n",
    "df_descriptions_without_empty = df[\"newdescription\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_descriptions_without_empty.describe([0.1,0.15,0.20,0.25,0.30,0.75,0.85,0.90,0.92,0.95,0.97,0.98,0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Regrex for character removal\n",
    "import re\n",
    "\n",
    "# Spacy for spell check\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "\n",
    "# NLTK for tokenisation and lemmatization\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Spacy stop word creation\n",
    "stopping_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopping_words_new = stopping_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ca', 'last', 'indeed', 'because', 'next', 'per', 'mine', 'or', 'except', 'would', 'what', 'how', 'moreover', 'enough', 'using', 'various', 'mostly', 'the', 'many', 'whose', 'toward', 'via', 'well', 'never', 'hereby', 'sometime', '‘s', 'herein', 'five', 'others', 'often', 'several', 'i', 'whereas', 'anyone', '‘m', 'say', 'even', 'hereupon', 'above', 'everywhere', \"'s\", 'both', 'too', 'as', 'seems', 'put', 'by', 'your', 'rather', 'become', 'her', 'themselves', 'fifteen', 'third', 'together', 'twelve', 'us', 'perhaps', 'one', 'his', 'along', 'in', 'much', 'part', 'latterly', 'nevertheless', 'of', 'must', 'hence', 'will', 'from', 'our', 'besides', 'hers', \"'d\", 'under', 'being', 'alone', 'thereby', 'whether', 'behind', 'this', 'might', 'really', 'call', 'front', 'across', 'itself', 'seeming', 'serious', 'nothing', 'due', 'twenty', 'and', 'quite', 'still', 'do', 'upon', 'only', 'anything', 'can', 'first', 'around', 'three', 'myself', 'beforehand', 'wherever', 'which', 'unless', 're', 'towards', \"'ll\", 'nobody', 'again', 'done', 'since', 'every', 'thereupon', 'then', 'after', 'give', 'if', 'became', 'somehow', 'whole', 'please', '‘d', 'make', 'though', 'to', '‘ve', 'just', 'thru', 'same', '’re', \"'ve\", 'anyhow', 'all', '’m', 'be', 'before', 'either', 'its', 'wherein', 'those', 'whereupon', 'back', 'although', 'beside', 'am', 'hereafter', 'out', 'whoever', 'name', 'nowhere', 'them', 'an', 'is', 'regarding', 'else', 'each', 'something', 'elsewhere', 'ever', 'between', '’ve', 'me', 'may', 'does', 'noone', 'top', 'it', 'with', 'there', 'these', 'two', 'get', 'among', 'were', 'sixty', 'has', 'they', 'was', 'why', 'whereafter', 'former', 'on', '’d', 'n’t', 'whence', 'go', '‘re', 'ten', 'thus', 'have', 'through', 'seemed', 'during', 'sometimes', 'himself', 'nor', 'ours', 'empty', 'amongst', 'he', 'over', 'used', 'afterwards', 'other', 'someone', 'than', 'becomes', 'their', '’s', 'thereafter', 'move', 'made', 'that', 'any', 'eleven', 'few', 'now', 'onto', 'herself', 'more', 'a', 'everyone', 'when', 'always', 'formerly', 'could', 'bottom', 'here', 'side', 'four', 'own', 'yourselves', 'below', 'ourselves', 'cannot', 'already', 'up', 'whenever', 'keep', 'yourself', 'otherwise', 'yet', 'further', \"'re\", 'eight', 'anywhere', '‘ll', 'latter', 'least', 'should', 'did', 'but', 'down', 'hundred', 'she', 'such', 'very', 'you', 'thence', 'had', 'most', 'take', 'meanwhile', 'at', 'n‘t', 'see', 'whom', 'whereby', 'namely', 'doing', 'him', 'another', 'we', 'until', 'whatever', 'against', 'beyond', '’ll', 'neither', 'while', 'off', 'somewhere', 'fifty', 'amount', 'where', 'who', 'therefore', \"n't\", 'into', 'are', 'everything', 'show', 'also', 'whither', 'been', 'throughout', 'full', 'once', 'yours', 'forty', 'nine', 'seem', 'therein', 'within', \"'m\", 'so', 'some', 'however', 'becoming', 'almost', 'anyway', 'my', 'six', 'for', 'about'}\n"
     ]
    }
   ],
   "source": [
    "stopping_words_to_remove = ['without' , 'not', 'less', 'noting', 'none','no']\n",
    "for word in list(stopping_words_new):\n",
    "    if word in stopping_words_to_remove:\n",
    "        stopping_words_new.remove(word)\n",
    "print(stopping_words_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of descriptions\n",
    "\n",
    "def preprocessing(raw_string):\n",
    "    # Remove html tags and anything inside them \n",
    "    no_html = re.sub(r'<[^>]*>','', raw_string)\n",
    "    #print(\"after removing html\", no_html)\n",
    "\n",
    "\n",
    "    # Make everything lowercase\n",
    "    lowercase_column = no_html.lower()\n",
    "    #print(\"lowercase\", lowercase_column)\n",
    "\n",
    "    # Remove apostrophe to enable spell check to correct words with apostrophe\n",
    "    without_apostrophe = re.sub(r'[\\']', '', lowercase_column)\n",
    "\n",
    "    # ! Need to double check again where best to use this spell check\n",
    "    # \n",
    "    # .pipe for batches of text\n",
    "    #doc = list(nlp.pipe(without_apostrophe))\n",
    "    #doc = nlp(without_apostrophe)\n",
    "\n",
    "    #spell_checked = doc._.outcome_spellCheck\n",
    "\n",
    "    # Remove all non alphabetic instances that aren't a space and replace them with a space using Regrex\n",
    "    alphabetic_column = re.sub(r'[^a-z\\s]', ' ', without_apostrophe)\n",
    "    #print(\"removed numerical and punctuation\", alphabetic_column)\n",
    "\n",
    "    # Tokenize string into individual words\n",
    "    tokens = word_tokenize(alphabetic_column)\n",
    "\n",
    "    # Remove stopping words using Spacy library\n",
    "    tokens_without_stopping_words = [token for token in tokens if token not in stopping_words_new]\n",
    "\n",
    "    # Lemmatize tokens using nltk and join them into sentances\n",
    "    sentances_without_stop_words = ' '.join([lemmatizer.lemmatize(t) for t in tokens_without_stopping_words])\n",
    "\n",
    "    return sentances_without_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        loud n clear personal sound amplifier allows t...\n",
       "2        no stay perfect foundation stay perfect longer...\n",
       "4        lacto calamine skin balance daily nourishing l...\n",
       "5        mary kay satin hand peach hand cream travel si...\n",
       "7        according legend brother native origin black b...\n",
       "                               ...                        \n",
       "32879                                                  NaN\n",
       "32880                                                  NaN\n",
       "32884                                                  NaN\n",
       "32885                                                  NaN\n",
       "32890                                                  NaN\n",
       "Name: clean_description, Length: 10710, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_description\"] = df[\"newdescription\"].head(1000).apply(preprocessing)\n",
    "\n",
    "df[\"clean_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any empty descriptions that appear because of head()\n",
    "df = df.drop(df[ ( (df[\"clean_description\"] == \"\" ) | ( df[\"clean_description\"].isnull()) ) ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.00000\n",
       "mean       44.84100\n",
       "std        32.72263\n",
       "min         4.00000\n",
       "3%          9.00000\n",
       "10%        13.00000\n",
       "20%        19.00000\n",
       "30%        24.70000\n",
       "50%        35.00000\n",
       "75%        59.00000\n",
       "85%        76.15000\n",
       "90%        92.00000\n",
       "95%       114.00000\n",
       "max       221.00000\n",
       "Name: clean_description, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying range of descriptions in after cleaning\n",
    " \n",
    "df_description_without_empty_clean = df[\"clean_description\"].apply(lambda x: len(x.split()))\n",
    "#df_descriptions_without_empty.describe()\n",
    "df_description_without_empty_clean.describe([0.03,0.1,0.2,0.3,0.75,0.85,0.90,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skin', 762),\n",
       " ('hair', 372),\n",
       " ('oil', 288),\n",
       " ('use', 270),\n",
       " ('natural', 268),\n",
       " ('product', 266),\n",
       " ('body', 229),\n",
       " ('fragrance', 214),\n",
       " ('help', 207),\n",
       " ('not', 178),\n",
       " ('oz', 174),\n",
       " ('clean', 171),\n",
       " ('free', 170),\n",
       " ('formula', 162),\n",
       " ('shave', 156),\n",
       " ('dry', 151),\n",
       " ('no', 146),\n",
       " ('color', 141),\n",
       " ('smooth', 135),\n",
       " ('soft', 134),\n",
       " ('x', 130),\n",
       " ('day', 129),\n",
       " ('ingredient', 128),\n",
       " ('vitamin', 126),\n",
       " ('time', 117),\n",
       " ('blend', 115),\n",
       " ('soap', 113),\n",
       " ('long', 111),\n",
       " ('scent', 110),\n",
       " ('system', 109),\n",
       " ('size', 107),\n",
       " ('water', 107),\n",
       " ('shaving', 106),\n",
       " ('head', 105),\n",
       " ('blade', 103),\n",
       " ('extract', 102),\n",
       " ('line', 99),\n",
       " ('face', 97),\n",
       " ('easy', 97),\n",
       " ('contains', 96),\n",
       " ('nbsp', 96),\n",
       " ('organic', 94),\n",
       " ('bath', 94),\n",
       " ('provides', 93),\n",
       " ('hand', 92),\n",
       " ('designed', 92),\n",
       " ('razor', 91),\n",
       " ('cream', 89),\n",
       " ('note', 87),\n",
       " ('lip', 86),\n",
       " ('e', 84),\n",
       " ('essential', 84),\n",
       " ('woman', 82),\n",
       " ('work', 82),\n",
       " ('perfect', 81),\n",
       " ('area', 81),\n",
       " ('amp', 81),\n",
       " ('without', 80),\n",
       " ('new', 79),\n",
       " ('trimmer', 79),\n",
       " ('gel', 79),\n",
       " ('xl', 79),\n",
       " ('lotion', 77),\n",
       " ('remove', 77),\n",
       " ('minute', 75),\n",
       " ('gently', 75),\n",
       " ('wear', 74),\n",
       " ('design', 74),\n",
       " ('shaver', 74),\n",
       " ('great', 74),\n",
       " ('light', 74),\n",
       " ('feature', 73),\n",
       " ('gentle', 73),\n",
       " ('fresh', 72),\n",
       " ('moisture', 72),\n",
       " ('year', 71),\n",
       " ('leaf', 71),\n",
       " ('rich', 70),\n",
       " ('pure', 70),\n",
       " ('shine', 68),\n",
       " ('treatment', 68),\n",
       " ('brush', 68),\n",
       " ('healthy', 68),\n",
       " ('eye', 68),\n",
       " ('fit', 67),\n",
       " ('sensitive', 66),\n",
       " ('comfortable', 65),\n",
       " ('spray', 65),\n",
       " ('tea', 65),\n",
       " ('quality', 64),\n",
       " ('come', 64),\n",
       " ('apply', 63),\n",
       " ('non', 62),\n",
       " ('feel', 62),\n",
       " ('need', 61),\n",
       " ('unique', 60),\n",
       " ('way', 60),\n",
       " ('protection', 60),\n",
       " ('looking', 60),\n",
       " ('care', 60)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(\" \".join(df[\"clean_description\"]).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lda import guidedlda as glda\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "model = glda.GuidedLDA(n_topics=4, n_iter=2000, random_state=7, refresh=20,alpha=0.01,eta=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
